{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVsd_-pwonHh"
   },
   "source": [
    "In the final project you will develop your own classification algorithm based on probabilistic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "QGomL4UnonHj",
    "outputId": "dd285558-454e-4a2c-e835-29f4b63764fa",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomas zapata sierra medellin colombia  de mayo de  es productor de cine y de teatrocita requerida\n",
      "sad eyed lady of the lowlands en espanol senorita de ojos tristes de las tierras bajas es una cancion compuesta por el cantante estadounidense bob dylan fue incluida en el album blonde on blonde editado el  de mayo de \n",
      "la revista mojo la coloco en el puesto  de su lista de las  mejores canciones de bob dylan\n",
      "calyptocephalella canqueli es una especie extinta de anfibio anuro perteneciente al genero c\n"
     ]
    }
   ],
   "source": [
    "with open(\"DataFP/Spanish.txt\") as f:\n",
    "    print(f.read(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "in7YYpE4onHk",
    "outputId": "95746c59-db7e-4d52-f559-b5a5262cbeb5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "riedhofe ist der name von ortsteilen in deutschland\n",
      "\n",
      "in badenwurttemberg\n",
      "riedhofe langenau ortsteil der stadt langenau im albdonaukreis\n",
      "riedhofe frickingen ortsteil der gemeinde frickingen im bodenseekreis\n",
      "riedhofe riegel am kaiserstuhl ortsteil der gemeinde riegel am kaiserstuhl im landkreis emmendingen\n",
      "riedhofe kongen ortsteil der gemeinde kongen im landkreis esslingen\n",
      "riedhofe leingarten ortsteil der gemeinde leingarten im landkreis heilbronn\n",
      "riedhofe bad wurzach ortsteil der stadt bad wurzac\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/User/Downloads/DataFP/German.txt\") as f:\n",
    "    print(f.read(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSlexPmBonHl"
   },
   "source": [
    "This is our training data. These texts are preprocessed: only standard Latin characters kept, diacritics removed, punctuations removed, all letters converted to lowercase. We will use similar preprocessing for new texts that we have to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YtkQsA0onHm"
   },
   "source": [
    "Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "9pmmgKsZonHn"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "### FROM: https://stackoverflow.com/a/518232/3025981\n",
    "def strip_accents(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "### END FROM\n",
    "\n",
    "def clean_text(s):\n",
    "    return re.sub(\"[^a-z \\n]\", \"\", strip_accents(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PncO_AQonHp"
   },
   "source": [
    "First of all, we have to find character relative frequencies in texts of each language. We will consider them as probability for character to appear in our multinomial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "JBA_XsgYonHq",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bcf26fb5354210c1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_freqs(text, relative=False):\n",
    "    return dict(Counter(list(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_probs = {}\n",
    "lan = ('Polish', 'English', 'Italian', 'Spanish', 'German', 'French', 'Portuguese')\n",
    "\n",
    "for lang in lan:\n",
    "    with open('C:/Users/User/Downloads/DataFP/' + lang + '.txt') as f:\n",
    "        language = clean_text(strip_accents(f.read()))\n",
    "        freqs = get_freqs(language)\n",
    "        total_chars = sum(freqs.values())\n",
    "        lang_to_probs[lang] = {char: freq / total_chars for char, freq in freqs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IT9Az6EonHs"
   },
   "source": [
    "\n",
    "Now let us start implementing the actual classifier.\n",
    "\n",
    "Function return probability to obtain these absolute frequencies from multinomial distribution with given probabilities $P((X_1 = f_1) \\cap (X_2 = f_2) \\cap \\ldots \\cap (X_k = f_k))$ provided that $(X_1, \\ldots, X_k)$ is a system of multinomially distributed values with probabilities $(p_1, \\ldots, p_k)$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def multinomial_likelihood(probs, freqs):\n",
    "    coef = math.factorial(sum(freqs.values()))\n",
    "    for freq in freqs.values():\n",
    "        coef /= math.factorial(freq)\n",
    "\n",
    "    prob = coef\n",
    "    for symb, freq in freqs.items():\n",
    "        prob *= (probs[symb] ** freq)\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4q3K8je2onHt"
   },
   "source": [
    "Let's find likelihood of data with frequencies `{'a': 2, 'b': 1, 'c': 2}` and probabilities `{'a': 0.2, 'b': 0.5, 'c': 0.3}`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "QoqTTC0ionHt",
    "outputId": "e625aebf-1dfd-4f46-d1bd-a5c21aa79306",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054000000000000006"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_likelihood(probs={'a': 0.2, 'b': 0.5, 'c': 0.3}, freqs={'a': 2, 'b': 1, 'c': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8csAFr_YonHu"
   },
   "source": [
    "Note that the coefficient with factorials depends only on `freqs` and does not depend on `probs`. It means that for all possible languages this coefficient will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "CzH6sstIonHu",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99bfc1e01b6b804e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def multinomial_likelihood_without_coeff(probs, freqs):\n",
    "    prob = 1\n",
    "    for symb, freq in freqs.items():\n",
    "        prob *= (probs[symb] ** freq)\n",
    "    return prob    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pH5vtbPhonHu"
   },
   "source": [
    "Corresponding probability become smaller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "AWxoGtbKonHu",
    "outputId": "9904bb33-64c1-41d5-9d67-034f4817ccab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018000000000000004"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_likelihood_without_coeff(probs={'a': 0.2, 'b': 0.5, 'c': 0.3},\n",
    "                                     freqs={'a': 2, 'b': 1, 'c': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-j68-jIAonHv"
   },
   "source": [
    "Actually, likelihoods become extremely small very quickly when we increase absolute frequencies in data. It is not surprisingly: the probability to get the text that coincides with our actual text from random experiment we discussed is extremely small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "QC4HF-UaonHv",
    "outputId": "2052b3e0-d56d-4e63-9a6a-e5b151878435"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00018000000000000004"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_likelihood_without_coeff(probs={'a': 0.2, 'b': 0.5, 'c': 0.3},\n",
    "                    freqs={'a': 3, 'b': 2, 'c': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "8nSWUd2fonHv",
    "outputId": "048ad04b-92d4-441e-9e55-e51579afe1b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.866455078125001e-10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_likelihood_without_coeff(probs={'a': 0.2, 'b': 0.5, 'c': 0.3},\n",
    "                    freqs={'a': 3, 'b': 20, 'c': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i57kmLponHv"
   },
   "source": [
    "Due to limited precision of computer arithmetic, for frequencies large enough we will get exactly zero likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "cWeiFPtvonHv",
    "outputId": "09f518fc-17b4-44b1-9860-375fbe9a43ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_likelihood_without_coeff(probs={'a': 0.2, 'b': 0.5, 'c': 0.3},\n",
    "                                     freqs={'a': 543, 'b': 512, 'c': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzglPanqonHw"
   },
   "source": [
    "Thus we usually cannot use likelihoods like this directly. Common way to deal with such a tiny numbers is to use _logarithms_ instead of likelihood themself. Indeed, logarithm is monotonically increasing function. If we compare logarithms, it is equivalent to compare their arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "DjeFHu8MonHw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c6283b47bbcf5b95",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_likelihood_without_coeff(probs, freqs):\n",
    "    prob = 0\n",
    "    for symb, freq in freqs.items():\n",
    "        prob += freq * math.log(probs[symb])\n",
    "    return prob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQyt3Yu9onHw"
   },
   "source": [
    "Likelihoods are probabilities, so they are less than 1 and their logarithms are negative. The larger absolute value of log-likelihood, the less is likelihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "5bS5HxvponHw",
    "outputId": "fb5f1e01-e573-42e7-ef86-22ea0722b9fc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.319968614080018"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood_without_coeff(probs={'a': 0.2, 'b': 0.5, 'c': 0.3},\n",
    "                             freqs={'a': 2, 'b': 1, 'c': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1E5IspSonHw"
   },
   "source": [
    "Now we can deal with inputs that lead to exact zero value previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "iToxFlQxonHw",
    "outputId": "97fefa05-e2f4-4e7d-a897-205fe2768eb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1231.2240885070605"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood_without_coeff(probs={'a': 0.2, 'b': 0.5, 'c': 0.3},\n",
    "                             freqs={'a': 543, 'b': 512, 'c': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl0iOhJPonHx"
   },
   "source": [
    "Now we will use likelihood to choose the best language for some text we want to classify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "dM8wxxcRonHx",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-761e62cc0f17dc2d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mle_best(text, lang_to_probs):\n",
    "    text = clean_text(strip_accents(text))\n",
    "    freqs = get_freqs(text)\n",
    "    res = {}\n",
    "    for k, v in lang_to_probs.items():\n",
    "        res[k] = res.get(k, log_likelihood_without_coeff(v, freqs)) \n",
    "        \n",
    "    return max(res.items(), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "zcIgYjYEonHx",
    "outputId": "18de8347-52a5-42bb-98dc-a91c20298e3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://en.wikipedia.org/wiki/1134_Kepler\n",
    "text = \"\"\"1134 Kepler, provisional designation 1929 SA, is a stony asteroid \n",
    "and eccentric Mars-crosser from the asteroid belt, approximately \n",
    "4 kilometers in diameter\"\"\"\n",
    "mle_best(text, lang_to_probs) #'English'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "eebo3vi7onHy",
    "outputId": "4be101bc-9ac4-4bf6-c205-c356bafb2e88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polish'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://pl.wikipedia.org/wiki/(1134)_Kepler\n",
    "text = \"\"\"\"(1134) Kepler – planetoida z grupy przecinających \n",
    "orbitę Marsa okrążająca Słońce w ciągu 4 lat i 145 dni \n",
    "w średniej odległości 2,68 au.\n",
    "\"\"\"\n",
    "mle_best(text, lang_to_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "z5-vM4T5onHy",
    "outputId": "717d4028-90f9-4ce6-dedf-c6f17c9bb7df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italian'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://it.wikipedia.org/wiki/1134_Kepler\n",
    "text = \"\"\"1134 Kepler è un asteroide areosecante. Scoperto nel 1929, \n",
    "presenta un'orbita caratterizzata da un semiasse maggiore pari a 2,6829098 \n",
    "UA e da un'eccentricità di 0,4651458, inclinata di 15,17381° rispetto\n",
    "\"\"\"\n",
    "mle_best(text, lang_to_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYWQTULZonHy"
   },
   "source": [
    "Assume that we selected random article from all Wikipedia articles in languages that we consider. There are different number of articles in different languages, so it is more likely to obtain article e.g. in English than in Polish (at least, at this moment). It means that we need stronger evidence for Polish to accept it comparing with English. To take into account this information, we will use Bayes' rule as discussed in the videos.\n",
    "\n",
    "Recall that in Bayessian approach we consider _prior_ probabilities of languages, then use Bayes' rule to find their posterior probabilies and select language with largest posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "RnDs7oOeonHy",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1076e90562dad99c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lang_to_prior = {'English': 6090/16410, 'Italian': 1611/16410, 'Spanish': 1602/16410, 'German': 2439/16410, \n",
    "                 'French': 2222/16410, 'Polish': 1412/16410, 'Portuguese': 1034/16410}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "A7AFgrY9onHz",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1725db02a8cb77ad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def bayesian_best(text, lang_to_probs, lang_to_prior):\n",
    "    text = clean_text(strip_accents(text))\n",
    "    freqs = get_freqs(text)\n",
    "    res = {}\n",
    "    for k, v in lang_to_probs.items():\n",
    "        res[k] = res.get(k, log_likelihood_without_coeff(v, freqs)+ math.log(lang_to_prior[k])) \n",
    "        \n",
    "    return max(res.items(), key=lambda x: x[1])[0]    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ro9QObUJonHz"
   },
   "source": [
    "For example, MLE algorithm believes that word `\"The\"` belongs go German language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "N6_gz6rbonHz",
    "outputId": "fd04fd11-d1b3-4416-b6d3-7697c6f71408"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle_best(\"The\", lang_to_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCH74x-GonHz"
   },
   "source": [
    "However, if we take into account that English is more popular in Wikipdia, results changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "v8LfC6ToonHz"
   },
   "outputs": [],
   "source": [
    "bayesian_best(\"The\", lang_to_probs, lang_to_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9RMCkxfonH0"
   },
   "source": [
    "Finally, let us get posterior probability how certain our Bayesian algorithm in its classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "c0epuiy4onH0",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8705f891f8eff4f7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def bayesian_posterior(text, lang_to_probs, lang_to_prior, test_lang):\n",
    "    text = clean_text(strip_accents(text))\n",
    "    freqs = get_freqs(text)\n",
    "    posterior = {}\n",
    "    \n",
    "    for lang, probs in lang_to_probs.items():\n",
    "        likelihood = multinomial_likelihood(probs, freqs)\n",
    "        posterior[lang] = likelihood * lang_to_prior[lang]\n",
    "        \n",
    "    total_posterior = sum(posterior.values())\n",
    "    for lang in posterior:\n",
    "        posterior[lang] /= total_posterior\n",
    "    \n",
    "    return posterior[test_lang]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "mAOwAYnponH0",
    "outputId": "8502a5c0-1610-467b-9545-d91ce1c9779c"
   },
   "outputs": [],
   "source": [
    "bayesian_posterior(\"The\", lang_to_probs, lang_to_prior, \"German\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "sUVZPTiPonH0",
    "outputId": "703c7d81-817c-479d-f8ec-358688a8deeb"
   },
   "outputs": [],
   "source": [
    "bayesian_posterior(\"The\", lang_to_probs, lang_to_prior, \"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "NdIeqtygonH0",
    "outputId": "b73f8a5e-1a84-43eb-fffc-b19bb9146fa3"
   },
   "outputs": [],
   "source": [
    "bayesian_posterior(\"Das\", lang_to_probs, lang_to_prior, \"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "pm21A6zvonH0",
    "outputId": "07633b01-904b-4598-a7a4-6c3a74f73402"
   },
   "outputs": [],
   "source": [
    "bayesian_posterior(\"Das\", lang_to_probs, lang_to_prior, \"German\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NY-Bm5lonH0"
   },
   "source": [
    "We see that our algorithm believes that `\"Das\"` belongs to English. This is due to small amount of data (only three letters!) and high prior for English. However, it is not very certain: the posterior is only 0.37. On the other hand, `\"The\"` belongs to `\"English\"` with much larger posterior probability."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
